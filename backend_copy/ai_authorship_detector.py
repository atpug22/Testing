"""
AI Authorship Detection Module
Analyzes code patterns to detect AI-generated content in pull requests.
"""

import re
import json
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime

from ai_impact_models import AIAuthorshipResult, AIConfidenceLevel


class AIAuthorshipDetector:
    """Detects AI authorship in code using pattern analysis"""
    
    def __init__(self):
        # AI-indicative patterns (improved from previous version)
        self.ai_comment_patterns = [
            r'# This code was generated',
            r'// Generated by',
            r'# AI-generated',
            r'// Auto-generated',
            r'# Created with assistance',
            r'// Created using',
        ]
        
        # Common AI coding patterns
        self.ai_code_patterns = [
            r'def\s+\w+\(\s*\)\s*:\s*""".*?"""',  # Empty functions with docstrings
            r'# TODO:.*implement',  # AI often leaves TODO comments
            r'pass\s*#.*placeholder',  # Placeholder implementations
            r'raise\s+NotImplementedError\(\s*["\'].*["\']?\s*\)',  # NotImplementedError patterns
        ]
        
        # Commit message patterns
        self.ai_commit_patterns = [
            r'fix.*issue.*#\d+',
            r'implement.*feature.*as.*requested',
            r'add.*functionality.*for.*\w+',
            r'update.*code.*to.*handle.*\w+',
            r'refactor.*\w+.*for.*better.*\w+',
        ]
        
        # File change patterns that suggest AI
        self.ai_file_patterns = {
            'large_single_commits': 500,  # Lines changed in single commit
            'multiple_file_types': 5,     # Different file extensions in one PR
            'test_to_code_ratio': 0.3,    # Low test coverage ratio
        }

    def analyze_pr(self, pr_data: Dict[str, Any]) -> AIAuthorshipResult:
        """Analyze a PR for AI authorship indicators"""
        pr_number = pr_data.get('number', 0)
        
        # Initialize analysis
        indicators = []
        ai_score = 0.0
        file_analysis = {}
        commit_patterns = {}
        
        # Analyze PR files if available
        if 'files' in pr_data and pr_data['files']:
            file_score, file_indicators, file_details = self._analyze_files(pr_data['files'])
            ai_score += file_score
            indicators.extend(file_indicators)
            file_analysis = file_details
        
        # Analyze commits if available
        if 'commits' in pr_data and pr_data['commits']:
            commit_score, commit_indicators, commit_details = self._analyze_commits(pr_data['commits'])
            ai_score += commit_score
            indicators.extend(commit_indicators)
            commit_patterns = commit_details
        
        # Analyze PR metadata
        meta_score, meta_indicators = self._analyze_pr_metadata(pr_data)
        ai_score += meta_score
        indicators.extend(meta_indicators)
        
        # Normalize score and determine confidence
        ai_probability = min(ai_score / 3.0, 1.0)  # Normalize to 0-1
        confidence = self._determine_confidence(ai_probability, len(indicators))
        
        return AIAuthorshipResult(
            pr_number=pr_number,
            confidence=confidence,
            ai_probability=ai_probability,
            indicators=indicators,
            file_analysis=file_analysis,
            commit_patterns=commit_patterns
        )

    def _analyze_files(self, files: List[Dict[str, Any]]) -> Tuple[float, List[str], Dict[str, Any]]:
        """Analyze file changes for AI patterns"""
        score = 0.0
        indicators = []
        details = {
            'total_files': len(files),
            'file_types': set(),
            'total_additions': 0,
            'total_deletions': 0,
            'large_files': 0,
            'ai_pattern_matches': 0
        }
        
        for file_data in files:
            filename = file_data.get('filename', '')
            additions = file_data.get('additions', 0)
            deletions = file_data.get('deletions', 0)
            patch = file_data.get('patch', '')
            
            # Track file types
            if '.' in filename:
                ext = filename.split('.')[-1]
                details['file_types'].add(ext)
            
            details['total_additions'] += additions
            details['total_deletions'] += deletions
            
            # Check for large single-file changes
            if additions > self.ai_file_patterns['large_single_commits']:
                details['large_files'] += 1
                score += 0.3
                indicators.append(f"Large file change: {filename} (+{additions} lines)")
            
            # Analyze patch content for AI patterns
            if patch:
                ai_matches = self._find_ai_patterns_in_patch(patch)
                if ai_matches:
                    details['ai_pattern_matches'] += len(ai_matches)
                    score += 0.2 * len(ai_matches)
                    indicators.extend([f"AI pattern in {filename}: {match}" for match in ai_matches])
        
        # Multiple file types in one PR (common with AI)
        if len(details['file_types']) >= self.ai_file_patterns['multiple_file_types']:
            score += 0.4
            indicators.append(f"Multiple file types modified: {list(details['file_types'])}")
        
        return score, indicators, details

    def _analyze_commits(self, commits: List[Dict[str, Any]]) -> Tuple[float, List[str], Dict[str, Any]]:
        """Analyze commit patterns for AI indicators"""
        score = 0.0
        indicators = []
        details = {
            'total_commits': len(commits),
            'commit_messages': [],
            'ai_pattern_commits': 0,
            'avg_commit_size': 0
        }
        
        total_changes = 0
        
        for commit in commits:
            commit_info = commit.get('commit', {})
            message = commit_info.get('message', '')
            details['commit_messages'].append(message)
            
            # Check commit message patterns
            for pattern in self.ai_commit_patterns:
                if re.search(pattern, message, re.IGNORECASE):
                    details['ai_pattern_commits'] += 1
                    score += 0.2
                    indicators.append(f"AI-style commit message: {message[:50]}...")
                    break
            
            # Track commit size (if available)
            stats = commit.get('stats', {})
            if stats:
                changes = stats.get('additions', 0) + stats.get('deletions', 0)
                total_changes += changes
        
        if commits:
            details['avg_commit_size'] = total_changes / len(commits)
        
        return score, indicators, details

    def _analyze_pr_metadata(self, pr_data: Dict[str, Any]) -> Tuple[float, List[str]]:
        """Analyze PR metadata for AI indicators"""
        score = 0.0
        indicators = []
        
        title = pr_data.get('title', '')
        body = pr_data.get('body', '')
        
        # Check title patterns
        ai_title_patterns = [
            r'fix.*#\d+',
            r'implement.*feature',
            r'add.*support.*for',
            r'update.*to.*handle',
        ]
        
        for pattern in ai_title_patterns:
            if re.search(pattern, title, re.IGNORECASE):
                score += 0.1
                indicators.append(f"AI-style title pattern: {title}")
                break
        
        # Check body content
        if body:
            # Very short or very long descriptions can indicate AI
            if len(body) < 20:
                score += 0.1
                indicators.append("Very brief PR description")
            elif len(body) > 1000:
                score += 0.1
                indicators.append("Very detailed PR description")
            
            # Check for AI-generated description patterns
            ai_body_patterns = [
                r'this.*pr.*implements',
                r'changes.*include',
                r'fixes.*the.*following',
                r'addresses.*issue.*by',
            ]
            
            for pattern in ai_body_patterns:
                if re.search(pattern, body, re.IGNORECASE):
                    score += 0.1
                    indicators.append("AI-style description pattern")
                    break
        
        return score, indicators

    def _find_ai_patterns_in_patch(self, patch: str) -> List[str]:
        """Find AI-specific patterns in code patch"""
        matches = []
        
        # Check comment patterns
        for pattern in self.ai_comment_patterns:
            if re.search(pattern, patch, re.IGNORECASE):
                matches.append(f"AI comment: {pattern}")
        
        # Check code patterns
        for pattern in self.ai_code_patterns:
            if re.search(pattern, patch, re.IGNORECASE | re.DOTALL):
                matches.append(f"AI code pattern: {pattern}")
        
        return matches

    def _determine_confidence(self, ai_probability: float, indicator_count: int) -> AIConfidenceLevel:
        """Determine confidence level based on probability and indicators"""
        if ai_probability >= 0.7 and indicator_count >= 3:
            return AIConfidenceLevel.HIGH
        elif ai_probability >= 0.4 and indicator_count >= 2:
            return AIConfidenceLevel.MEDIUM
        elif ai_probability >= 0.2 or indicator_count >= 1:
            return AIConfidenceLevel.LOW
        else:
            return AIConfidenceLevel.UNKNOWN

    def batch_analyze_prs(self, prs_data: List[Dict[str, Any]]) -> List[AIAuthorshipResult]:
        """Analyze multiple PRs for AI authorship"""
        results = []
        for pr_data in prs_data:
            try:
                result = self.analyze_pr(pr_data)
                results.append(result)
            except Exception as e:
                # Create a failed result for this PR
                pr_number = pr_data.get('number', 0)
                results.append(AIAuthorshipResult(
                    pr_number=pr_number,
                    confidence=AIConfidenceLevel.UNKNOWN,
                    ai_probability=0.0,
                    indicators=[f"Analysis failed: {str(e)}"]
                ))
        
        return results
